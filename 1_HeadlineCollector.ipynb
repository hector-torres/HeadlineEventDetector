{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The Headline Collector\n",
    "---\n",
    "\n",
    "## Intro\n",
    "This notebook contains the code for collecting headlines from existing news aggregators.\n",
    "The purpose is two-fold: to test the reliability of news aggregators in event detection,\n",
    "and to provide a corpus of headlines on which to perform feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pygooglenews import GoogleNews\n",
    "\n",
    "def headline_importer() -> dict:\n",
    "\n",
    "    gn = GoogleNews()\n",
    "\n",
    "    # retrieves world headlines\n",
    "    news = gn.topic_headlines('WORLD', proxies=None, scraping_bee=None)\n",
    "\n",
    "    return news"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Persistence\n",
    "\n",
    "This prepare to save the data to disk or to database, depending on the desired storage\n",
    "medium.\n",
    "\n",
    "### API to DataFrame\n",
    "\n",
    "This cell converts data from the API call into a pandas DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def headline_to_dataframe(headline_dict: dict):\n",
    "    \"\"\"\n",
    "    Converts data from the Google News API to a pandas DataFrame for analysis.\n",
    "\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\"\n",
    "    # sets current datetime\n",
    "    current_datetime = datetime.datetime.utcnow()\n",
    "\n",
    "    # key/value pairs of column names from API to new data schema\n",
    "    column_names = {'published': 'headline_time_created', 'id': 'headline_id', 'title': 'headline_text',\n",
    "                    'title_detail': 'headline_language', 'source': 'headline_source', 'link': 'headline_url',\n",
    "                    'headline_time_imported': 'headline_time_imported'}\n",
    "\n",
    "    # create new pandas DataFrame from API dictionary's 'entries' values\n",
    "    headline_df = pd.DataFrame.from_dict(headline_dict['entries'])\n",
    "\n",
    "    # keep only necessary columns\n",
    "    headline_df = headline_df[['published', 'id', 'title', 'title_detail', 'source', 'link']]\n",
    "\n",
    "    # overrides nested dictionaries in API values with Series object dervied from nested values\n",
    "    headline_df['title_detail'] = headline_df['title_detail'].apply(pd.Series)['language']\n",
    "    headline_df['source'] = headline_df['source'].apply(pd.Series)['title']\n",
    "    headline_df.published = pd.to_datetime(headline_df.published)\n",
    "\n",
    "    # creates new columns with current datetime\n",
    "    headline_df['headline_time_imported'] = current_datetime\n",
    "\n",
    "    # renames columns to match new data schema\n",
    "    headline_df.rename(columns=column_names, inplace=True)\n",
    "    headline_df.set_index('headline_id', inplace=True)\n",
    "\n",
    "    # convert headline_text column into stand-alone Series object\n",
    "    headline_text_series = headline_df.headline_text\n",
    "\n",
    "    # converts headline_source to list and adds it to a regex patter\n",
    "    headline_source_list = headline_df.headline_source.to_list()\n",
    "    pattern = '|'.join(headline_source_list)\n",
    "\n",
    "    # replaces the headline_source text added at the end of the headline_text string by the API source\n",
    "    headline_text_series = headline_text_series.str.replace(pattern, '')\n",
    "    # removes the last three characters of the headline_text (' - ' after stripping the source name)\n",
    "    headline_text_series = headline_text_series.str.slice(stop=-3)\n",
    "\n",
    "\n",
    "    # replaced original headline_text column with newly created Series\n",
    "    headline_df.headline_text = headline_text_series\n",
    "\n",
    "    return headline_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataFrame to File\n",
    "\n",
    "This cell checks to see if data in the DataFrame is already in our data file, and only saves data if it is\n",
    "not already present."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def dataframe_to_file(api_dataframe) -> None:\n",
    "    \"\"\"\n",
    "    Checks if data in DataFrame is present in target file, and saves DataFrame data that is not already\n",
    "    present.\n",
    "    :param api_dataframe: a DataFrame containing headline data\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # imports existing data file, if it already exists: if it doesn't exist, skips to creating file\n",
    "    directory_path = os.path.join('data', 'output')\n",
    "    file_path = os.path.join(directory_path, 'headlines.csv')\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            # creates a DataFrame object out of the last 1000 rows in our data file\n",
    "            existing_dataframe = pd.read_csv(file_path, sep='\\t', index_col='headline_id')\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print('file found with no data: writing data for first time')\n",
    "            api_dataframe.to_csv(file_path, sep='\\t',\n",
    "                             header=['headline_time_created', 'headline_text',\n",
    "                                     'headline_language', 'headline_source', 'headline_url', 'headline_time_imported'],\n",
    "                             index_label='headline_id', index=True, mode='a')\n",
    "            exit(0)\n",
    "\n",
    "        print('appending to existing file and data')\n",
    "        # sort existing DataFrame by headline_time_created\n",
    "        existing_dataframe.sort_values(by='headline_time_created', axis=0, ascending=False,\n",
    "                                       inplace=True)\n",
    "        # limit to last 1000 rows\n",
    "        existing_dataframe = existing_dataframe.head(1000)\n",
    "        # compare the headline_id column in our data file DataFrame to the headline_id column in our\n",
    "        # incoming headline DataFrame and parse out only non-matched (new) rows\n",
    "        new_headlines_dataframe = api_dataframe.loc[api_dataframe.index.difference(existing_dataframe.index),]\n",
    "\n",
    "        # test print statements\n",
    "        print('number of headlines in CSV\\n' + str(existing_dataframe.shape[0]))\n",
    "        print('number of total headlines in incoming dataframe\\n' +\n",
    "              str(api_dataframe.shape[0]))\n",
    "        print('number of new headlines in incoming dataframe\\n' +\n",
    "              str(new_headlines_dataframe.shape[0]))\n",
    "        print('expected number of headlines in CSV after save\\n' +\n",
    "              str(existing_dataframe.shape[0] + new_headlines_dataframe.shape[0]))\n",
    "\n",
    "        # TODO: keeps adding header to CSV file\n",
    "        # appends the non-matched rows to our data file\n",
    "        new_headlines_dataframe.to_csv(file_path, header=False, sep='\\t', index_label='headline_id', index=True,\n",
    "                                       mode='a')\n",
    "\n",
    "    else:\n",
    "        print('no file found: writing file for first time')\n",
    "        api_dataframe.to_csv(file_path, sep='\\t',\n",
    "                             header=['headline_time_created', 'headline_text',\n",
    "                                     'headline_language', 'headline_source', 'headline_url', 'headline_time_imported'],\n",
    "                             index_label='headline_id', index=True, mode='a')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending to existing file and data\n",
      "number of headlines in CSV\n",
      "170\n",
      "number of total headlines in incoming dataframe\n",
      "70\n",
      "number of new headlines in incoming dataframe\n",
      "7\n",
      "expected number of headlines in CSV after save\n",
      "177\n"
     ]
    }
   ],
   "source": [
    "# runner\n",
    "headlines = headline_importer()\n",
    "headlines_dataframe = headline_to_dataframe(headlines)\n",
    "dataframe_to_file(headlines_dataframe)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}