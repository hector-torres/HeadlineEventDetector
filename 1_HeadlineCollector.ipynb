{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The Headline Collector\n",
    "---\n",
    "\n",
    "## Intro\n",
    "This notebook contains the code for collecting headlines from existing news aggregators.\n",
    "The purpose is two-fold: to test the reliability of news aggregators in event detection,\n",
    "and to provide a corpus of headlines on which to perform feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from pygooglenews import GoogleNews\n",
    "\n",
    "def headline_importer() -> dict:\n",
    "\n",
    "    gn = GoogleNews()\n",
    "\n",
    "    # retrieves top stories\n",
    "    top = gn.top_news()\n",
    "\n",
    "    return top"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Persistence\n",
    "\n",
    "This prepare to save the data to disk or to database, depending on the desired storage\n",
    "medium.\n",
    "\n",
    "### API to DataFrame\n",
    "\n",
    "This cell converts data from the API call into a pandas DataFrame."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def headline_to_dataframe(headline_dict: dict):\n",
    "    \"\"\"\n",
    "    Converts data from the Google News API to a pandas DataFrame for analysis.\n",
    "\n",
    "    :return: pandas DataFrame\n",
    "    \"\"\"\n",
    "    # key/value pairs of column names from API to new data schema\n",
    "    column_names = {'published': 'headline_time_created', 'id': 'headline_id', 'title': 'headline_text',\n",
    "                 'title_detail': 'headline_language', 'source': 'headline_source', 'link': 'headline_url'}\n",
    "\n",
    "    # create new pandas DataFrame from API dictionary's 'entries' values\n",
    "    headline_df = pd.DataFrame.from_dict(headline_dict['entries'])\n",
    "\n",
    "    # keep only necessary columns\n",
    "    headline_df = headline_df[['published', 'id', 'title', 'title_detail', 'source', 'link']]\n",
    "\n",
    "    # overrides nested dictionaries in API values with Series object dervices from nest values\n",
    "    headline_df['title_detail'] = headline_df['title_detail'].apply(pd.Series)['language']\n",
    "    headline_df['source'] = headline_df['source'].apply(pd.Series)['title']\n",
    "\n",
    "    # renames columns to match new data schema\n",
    "    headline_df.rename(columns=column_names, inplace=True)\n",
    "\n",
    "    return headline_df, column_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DataFrame to File\n",
    "\n",
    "This cell checks to see if data in the DataFrame is already in our data file, and only saves data if it is\n",
    "not already present."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0          headline_time_created     headline_id  \\\n",
      "0           0  Sat, 25 Jul 2020 15:58:00 GMT  52780948641976   \n",
      "1           1  Sat, 25 Jul 2020 19:08:00 GMT  52780948590446   \n",
      "2           2  Sat, 25 Jul 2020 15:52:14 GMT  52780942128508   \n",
      "3           3  Sat, 25 Jul 2020 22:06:00 GMT  52780944259638   \n",
      "4           4  Sat, 25 Jul 2020 09:00:00 GMT  52780951100143   \n",
      "\n",
      "                                       headline_text  headline_language  \\\n",
      "0  Tropical Storm Hanna upgrades to a hurricane, ...                NaN   \n",
      "1  Florida now has more coronavirus cases than Ne...                NaN   \n",
      "2  US officials raid Chinese consulate in Houston...                NaN   \n",
      "3  1 person stabbed as thousands protest in Portl...                NaN   \n",
      "4  Will Trumpâ€™s Abrupt Shift on Coronavirus Re-en...                NaN   \n",
      "\n",
      "      headline_source                                       headline_url  \n",
      "0               Chron  https://news.google.com/__i/rss/rd/articles/CB...  \n",
      "1                CNBC  https://news.google.com/__i/rss/rd/articles/CB...  \n",
      "2            Fox News  https://news.google.com/__i/rss/rd/articles/CB...  \n",
      "3                 CNN  https://news.google.com/__i/rss/rd/articles/CB...  \n",
      "4  The New York Times  https://news.google.com/__i/rss/rd/articles/CB...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def dataframe_to_file(api_dataframe, column_names: dict) -> None:\n",
    "    \"\"\"\n",
    "    Checks if data in DataFrame is present in target file, and saves DataFrame data that is not already\n",
    "    present.\n",
    "    :param dataframe: a DataFrame containing headline data\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # imports existing data file, if it already exists: if it doesn't exist, skips to creating file\n",
    "    directory_path = os.path.join('data', 'output')\n",
    "    file_path = os.path.join(directory_path, 'headlines.csv')\n",
    "    if os.path.isfile(file_path):\n",
    "        # creates a DataFrame object out of the last 1000 rows in our data file\n",
    "        existing_dataframe = pd.read_csv(file_path, sep='\\t')\n",
    "        # sort existing DataFrame by headline_time_created\n",
    "\n",
    "        # limit to last 1000 rows\n",
    "\n",
    "        # compares the headline_id column in our data file DataFrame to the headline_id column in our\n",
    "        # headline DataFrame\n",
    "\n",
    "\n",
    "        # parses out only the non-matched rows in our headline DataFrame\n",
    "\n",
    "\n",
    "        # appends the non-matched rows to our data file\n",
    "\n",
    "\n",
    "    else:\n",
    "        api_dataframe.to_csv(file_path, sep='\\t', header=list(column_names.values()), mode='a')\n",
    "\n",
    "\n",
    "headlines = headline_importer()\n",
    "headlines_dataframe, columns = headline_to_dataframe(headlines)\n",
    "dataframe_to_file(headlines_dataframe, columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def headline_to_csv(parsed_headline: list) -> None:\n",
    "    \"\"\"\n",
    "    Takes in a list of parsed fields from a headline entry and saves them to CSV file\n",
    "\n",
    "    :param parsed_headline: a list of parsed fields from a headline entry\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    directory_path = os.path.join('data', 'output')\n",
    "    file_path = os.path.join(directory_path, 'headlines.csv')\n",
    "\n",
    "    def duplicate_detector(file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Searches through headline_id in headline CSV file in order to prevent importing duplicate headlines.\n",
    "\n",
    "        :param: file_path: file path to the CSV file\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "        # print(df.headline_id)\n",
    "        # todo: finish the compare tool by importing both sets of data as dataframes\n",
    "        # and comparing them before writing them to the csv file. maybe turn the\n",
    "        # csv writers into pandas methods too?\n",
    "\n",
    "    if os.path.isfile(file_path):   # if CSV file already exists\n",
    "        with open(file_path, 'a') as f:\n",
    "            duplicate_detector(file_path)\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(parsed_headline)\n",
    "    else:                           # if CSV file does not exist\n",
    "        with open(file_path, 'a') as f:\n",
    "            writer = csv.writer(f, delimiter='\\t')\n",
    "            writer.writerow(['headline_time_created', 'headline_id', 'headline_text',\n",
    "                 'headline_language', 'headline_source', 'headline_url'])\n",
    "            writer.writerow(parsed_headline)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}